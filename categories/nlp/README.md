# ğŸ“ NLP è‡ªç„¶è¯­è¨€å¤„ç†

> æ–‡æœ¬å¤„ç†ã€è¯­è¨€æ¨¡å‹ã€å¯¹è¯ç³»ç»Ÿç­‰ NLP ç›¸å…³èµ„æº

[â† è¿”å›ä¸»é¡µ](../../README.md)

---

## ğŸ“‘ ç›®å½•

- [æ–‡æœ¬é¢„å¤„ç†](#æ–‡æœ¬é¢„å¤„ç†)
- [è¯å‘é‡](#è¯å‘é‡)
- [è¯­è¨€æ¨¡å‹](#è¯­è¨€æ¨¡å‹)
- [å¤§è¯­è¨€æ¨¡å‹ LLM](#å¤§è¯­è¨€æ¨¡å‹-llm)
- [å®è·µåº”ç”¨](#å®è·µåº”ç”¨)

---

## æ–‡æœ¬é¢„å¤„ç†

*å¾…æ·»åŠ ...*

---

## è¯å‘é‡

### Word Embedding

| èµ„æº | ç±»å‹ | è¯­è¨€ | æ¨èç†ç”± | è´¡çŒ®è€… |
|------|------|------|----------|--------|
| [Word Embedding and Word2Vec, Clearly Explained!!! - StatQuest](https://www.youtube.com/watch?v=viZrOnJclY0) | ğŸ“º è§†é¢‘ | ğŸ‡¬ğŸ‡§ è‹±æ–‡ | StatQuest é£æ ¼ï¼Œç®€æ´æ˜äº†åˆä¸¥è°¨åœ°è§£é‡Šå¾ˆé€‚åˆåˆå­¦è€…çš„è¯åµŒå…¥çš„æ•™ç¨‹ï¼Œä¾‹å­å¾ˆç›´è§‚ | ChailynCui |

### GloVe

*å¾…æ·»åŠ ...*

---

## è¯­è¨€æ¨¡å‹

### Transformer

| èµ„æº | ç±»å‹ | è¯­è¨€ | æ¨èç†ç”± | è´¡çŒ®è€… |
|------|------|------|----------|--------|
| [Transformer Neural Networks, ChatGPT's foundation, Clearly Explained!!! - StatQuest](https://www.youtube.com/watch?v=zxQyTK8quyY) | ğŸ“º è§†é¢‘ | ğŸ‡¬ğŸ‡§ è‹±æ–‡ | StatQuest ç»å…¸æ•™ç¨‹ï¼Œè¶…çº§æ¸…æ™°è®²è§£ Transformer ç¥ç»ç½‘ç»œï¼ŒChatGPT çš„åŸºç¡€æ¶æ„ï¼Œå¯è§†åŒ–è®²è§£é€šä¿—æ˜“æ‡‚ï¼Œè®²çš„è¶…çº§å¥½ï¼Œé€‚åˆåˆå­¦è€… | ChailynCui |
| [The Illustrated Transformer - Jay Alammar](https://jalammar.github.io/illustrated-transformer/) | ğŸ“ åšå®¢ | ğŸ‡¬ğŸ‡§ è‹±æ–‡ | å²ä¸Šæœ€ç»å…¸çš„ Transformer å¯è§†åŒ–æ•™ç¨‹ï¼Œç”¨å›¾è§£å’ŒåŠ¨ç”»æ¸…æ™°è§£é‡Š Transformer æ¶æ„ï¼Œè¢« MITã€Stanfordã€Harvard ç­‰é¡¶å°–å¤§å­¦è¯¾ç¨‹é‡‡ç”¨ | ChailynCui |

### BERT

*å¾…æ·»åŠ ...*

### GPT ç³»åˆ—

*å¾…æ·»åŠ ...*

---

## å¤§è¯­è¨€æ¨¡å‹ LLM

### Prompt Engineering

| èµ„æº | ç±»å‹ | è¯­è¨€ | æ¨èç†ç”± | è´¡çŒ®è€… |
|------|------|------|----------|--------|
| [ä¸AIç»“å¯¹ç¼–ç¨‹ï¼šå®ç”¨çš„ Prompt ä¼˜åŒ–æŠ€å·§](https://mp.weixin.qq.com/s/88XO2ooWkTuMJhhyQJ12MA) | ğŸ“± å…¬ä¼—å· | ğŸ‡¨ğŸ‡³ ä¸­æ–‡ | åˆ†äº«ä¸€äº›å¼€å‘ä¸­å®ç”¨çš„ Prompt ä¼˜åŒ–æŠ€å·§ï¼Œå¸®åŠ©å¼€å‘è€…æ›´é«˜æ•ˆåœ°ä¸ AI åä½œï¼Œå¯¹æˆ‘æ¥è¯´æŒºæœ‰ç”¨ | ChailynCui |

### RAG

*å¾…æ·»åŠ ...*

### Fine-tuning

*å¾…æ·»åŠ ...*

---

## å®è·µåº”ç”¨

### Seq2Seq æ¨¡å‹

| èµ„æº | ç±»å‹ | è¯­è¨€ | æ¨èç†ç”± | è´¡çŒ®è€… |
|------|------|------|----------|--------|
| [Sequence-to-Sequence (seq2seq) Encoder-Decoder Neural Networks, Clearly Explained!!! - StatQuest](https://www.youtube.com/watch?v=L8HKweZIOmg) | ğŸ“º è§†é¢‘ | ğŸ‡¬ğŸ‡§ è‹±æ–‡ | StatQuest æ•™ç¨‹ï¼Œæ¸…æ™°è§£é‡Š seq2seq å’Œ Encoder-Decoder æ¶æ„çš„å·¥ä½œåŸç†ï¼Œå¬å®Œé†é†çŒé¡¶ | ChailynCui |
| [Visualizing A Neural Machine Translation Model - Jay Alammar](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/) | ğŸ“ åšå®¢ | ğŸ‡¬ğŸ‡§ è‹±æ–‡ | è¶…èµçš„å¯è§†åŒ–åšå®¢ï¼Œç”¨åŠ¨ç”»æ¸…æ™°å±•ç¤º seq2seq å’Œ Attention æœºåˆ¶çš„å·¥ä½œåŸç†ï¼ŒMIT æ·±åº¦å­¦ä¹ è¯¾ç¨‹æ¨è | ChailynCui |
| [PyTorch Seq2Seq Tutorials](https://github.com/bentrevett/pytorch-seq2seq) | ğŸ’» ä»£ç  | ğŸ‡¬ğŸ‡§ è‹±æ–‡ | å®Œæ•´çš„ PyTorch seq2seq å®ç°æ•™ç¨‹ï¼Œä»åŸºç¡€ Encoder-Decoder åˆ° Attention æœºåˆ¶ï¼Œä»£ç æ¸…æ™°æ˜“æ‡‚ï¼Œé€‚åˆåŠ¨æ‰‹å®è·µ | ChailynCui |
| [TensorFlow NMT Tutorial](https://github.com/tensorflow/nmt) | ğŸ’» ä»£ç  | ğŸ‡¬ğŸ‡§ è‹±æ–‡ | TensorFlow å®˜æ–¹ NMT æ•™ç¨‹ï¼Œæ¶µç›–ä»åŸºç¡€åˆ° GNMT æ³¨æ„åŠ›æœºåˆ¶ï¼Œæœ‰è¯¦ç»†æ–‡æ¡£å’Œ Benchmark ç»“æœ | ChailynCui |

*å¾…æ·»åŠ æ›´å¤š...*

